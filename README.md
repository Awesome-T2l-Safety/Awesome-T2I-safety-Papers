# T2I-safety-Papers
[![Update Log](https://img.shields.io/badge/💡-Update_Log-informational.svg?style=flat)](README.md)
[![Report Error](https://img.shields.io/badge/🐛-Report_Error-yellow.svg?style=flat)](https://github.com/Awesome-T2l-Safety/T2I-safety-Papers/issues)
[![Pull Request](https://img.shields.io/badge/👐-Pull_Request-brightgreen.svg?style=flat)](https://github.com/Awesome-T2l-Safety/T2I-safety-Papers/pulls)

---
## Jailbreak Attack on Text-to-Image Models

#### [0] SneakyPrompt: Jailbreaking Text-to-image Generative Models 
- **🧑‍🔬 Author**: Yuchen Yang, Bo Hui, Haolin Yuan, Neil Gong, Yinzhi Cao
- **🏫 Affiliation**: Johns Hopkins University, Duke University
- **🔗 Link**: [[Code](https://github.com/Yuchen413/text2image_safety)] [[arXiv:2305.12082](https://arxiv.org/abs/2305.12082)]
- **📝 Note**: 🔥 (S&P 2024)

#### [1] MMA-Diffusion: MultiModal Attack on Diffusion Models
- **🧑‍🔬 Author**: Yijun Yang, Ruiyuan Gao, Xiaosen Wang, Tsung-Yi Ho, Nan Xu, Qiang Xu
- **🏫 Affiliation**: The Chinese University of Hong Kong, Huawei Singular Security Lab, Institute of Automation, Chinese Academy of Sciences, Beijing Wenge Technology Co. Ltd
- **🔗 Link**: [[Code](https://github.com/cure-lab/MMA-Diffusion)] [[arXiv:2311.17516](https://arxiv.org/abs/2311.17516)]
- **📝 Note**: 🔥 (CVPR2024)

#### [2] RIATIG: Reliable and Imperceptible Adversarial Text-to-Image Generation With Natural Prompts
- **🧑‍🔬 Author**: Han Liu, Yuhao Wu, Shixuan Zhai, Bo Yuan, Ning Zhang
- **🏫 Affiliation**: Washington University in St. Louis, Rutgers University
- **🔗 Link**: [[Code](https://github.com/WUSTL-CSPL/RIATIG)] [[CVPR:2023](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_RIATIG_Reliable_and_Imperceptible_Adversarial_Text-to-Image_Generation_With_Natural_Prompts_CVPR_2023_paper.pdf)]
- **📝 Note**: 🔥 (CVPR2023)

#### [3] Prompt Stealing Attacks Against Text-to-Image Generation Model
- **🧑‍🔬 Author**: Xinyue Shen, Yiting Qu, Michael Backes, Yang Zhang
- **🏫 Affiliation**: CISPA Helmholtz Center for Information Security
- **🔗 Link**: [[Code]] [[arXiv:2302.09923](https://arxiv.org/abs/2302.09923)]
- **📝 Note**: 🔥 (CVPR2024)

#### [4] Divide-and-Conquer Attack: Harnessing the Power of LLM to Bypass the Censorship of Text-to-Image Generation Model
- **🧑‍🔬 Author**: Yimo Deng, Huangxun Chen
- **🏫 Affiliation**: The Hong Kong University of Science and Technology, Northeastern University
- **🔗 Link**:  [[Code](https://github.com/researchcode001/Divide-and-Conquer-Attack)] [[arXiv:2302.09923](https://arxiv.org/abs/2312.07130)]
- **📝 Note**:

#### [5] SurrogatePrompt: Bypassing the Safety Filter of Text-To-Image Models via Substitution
- **🧑‍🔬 Author**: Zhongjie Ba, Jieming Zhong, Jiachen Lei, Peng Cheng, Qinglong Wang, Zhan Qin, Zhibo Wang, Kui Ren
- **🏫 Affiliation**: Zhejiang University, ZJU-Hangzhou Global Scientific and Technological Innovation Center, 
- **🔗 Link**: [[Code]] [[arXiv:2309.14122](https://arxiv.org/abs/2309.14122)]
- **📝 Note**:

---
## Defenses on Text-to-Image Models

#### [0] GuardT2I: Defending Text-to-Image Models from Adversarial Prompts
- **🧑‍🔬 Author**: Yijun Yang, Ruiyuan Gao, Xiao Yang, Jianyuan Zhong, Qiang Xu
- **🏫 Affiliation**: The Chinese University of Hong Kong, Hong Kong,  Tsinghua University
- **🔗 Link**: [[Code]] [[arXiv:2403.01446](https://arxiv.org/abs/2403.01446)]
- **📝 Note**:

#### [1] Universal Prompt Optimizer for Safe Text-to-Image Generation
- **🧑‍🔬 Author**: Zongyu Wu, Hongcheng Gao, Yueze Wang, Xiang Zhang, Suhang Wang
- **🏫 Affiliation**: The Pennsylvania State University, University of Chinese Academy of Sciences, Tianjin University
- **🔗 Link**: [[Code]] [[arXiv:2402.10882](https://arxiv.org/abs/2402.10882)]
- **📝 Note**: 


#### [2] SAFEGEN: Mitigating Unsafe Content Generation in Text-to-Image Models
- **🧑‍🔬 Author**: Xinfeng Li, Yuchen Yang, Jiangyi Deng, Chen Yan, Yanjiao Chen, Xiaoyu Ji, Wenyuan Xu
- **🏫 Affiliation**: USSLAB, Zhejiang University, Johns Hopkins University
- **🔗 Link**: [[Code]] [[arXiv:2404.06666](https://arxiv.org/abs/2404.06666)]
- **📝 Note**: 

### Acknowledgement
Thanks to the [3D-Gaussian-Splatting-Papers](https://github.com/Awesome3DGS/3D-Gaussian-Splatting-Papers).
